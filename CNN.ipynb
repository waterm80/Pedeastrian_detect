{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJSe26eYbMyIsfGUBWbMYl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waterm80/Pedestrian_detect/blob/master/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Efk6fOeO3TK3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets ,models,transforms\n",
        "from pathlib import Path\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Conv2d, MaxPool2d, Module\n",
        "from torch.optim import Adam\n",
        "import pandas as pd\n",
        "import os\n",
        "from os import listdir\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJK-28Bzq2ha",
        "outputId": "76002c09-2a27-4aec-f638-625c3e54a0c5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_train=\"/content/drive/MyDrive/img/labeled\"\n",
        "TRAIN = Path(PATH_train)\n",
        "\n",
        "batch_size = 8\n",
        "LR = 0.0001\n",
        "\n",
        "transforms = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "NAAc88FJ3eTV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.ImageFolder(TRAIN, transform=transforms)\n",
        "\n",
        "train_size = int(0.7 * len(train_data))\n",
        "valid_size = len(train_data) - train_size\n",
        "train_data, valid_data = torch.utils.data.random_split(train_data, [train_size, valid_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "r1KtcCdm3u23"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN_Model, self).__init__()\n",
        "    # input_shape=(3,224,224)\n",
        "    self.cnn1 = nn.Conv2d(3, 16, kernel_size=5, stride=1) \n",
        "    self.relu1 = nn.ReLU(inplace=True) \n",
        "    # input_shape=(3,220,220)\n",
        "    self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    # input_shape=(16,110,110)\n",
        "    self.cnn2 = nn.Conv2d(16,8, kernel_size=11, stride=1) \n",
        "    self.relu2 = nn.ReLU(inplace=True) \n",
        "    # input_shape=(8,100,100)\n",
        "    self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
        "    # input_shape=(8,50,50)\n",
        "    self.fc = nn.Linear(8 * 50 * 50, 2)     \n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.cnn1(x) \n",
        "    out = self.relu1(out)\n",
        "    out = self.maxpool1(out)\n",
        "    out = self.cnn2(out)\n",
        "    out = self.relu2(out)\n",
        "    out = self.maxpool2(out)\n",
        "    out = out.view(out.size(0), -1) \n",
        "    out = self.fc(out) \n",
        "    return out"
      ],
      "metadata": {
        "id": "8DTMLR1D6-P3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, n_epochs, train_loader, valid_loader, optimizer, criterion):\n",
        "\n",
        "  train_acc_his,valid_acc_his=[],[]\n",
        "  train_losses_his,valid_losses_his=[],[]\n",
        "\n",
        "  for epoch in range(1, n_epochs+1):\n",
        "      # keep track of training and validation loss\n",
        "      train_loss, valid_loss = 0.0,0.0\n",
        "      train_losses ,valid_losses=[],[]\n",
        "      train_correct, val_correct, train_total, val_total=0,0,0,0\n",
        "      train_pred, train_target=torch.zeros(8,1), torch.zeros(8,1)\n",
        "      val_pred, val_target=torch.zeros(8,1), torch.zeros(8,1)\n",
        "      count=0\n",
        "      count2=0\n",
        "      print('running epoch: {}'.format(epoch))\n",
        "      ###################\n",
        "      # train the model #\n",
        "      ###################\n",
        "      model.train()\n",
        "      for data, target in tqdm(train_loader):\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = model(data)\n",
        "          # calculate the batch loss\n",
        "          loss = criterion(output, target)\n",
        "          #calculate accuracy\n",
        "          pred = output.data.max(dim = 1, keepdim = True)[1]\n",
        "          train_correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "          train_total += data.size(0)\n",
        "          # backward pass: compute gradient of the loss with respect to model parameters\n",
        "          loss.backward()\n",
        "          # perform a single optimization step (parameter update)\n",
        "          optimizer.step()\n",
        "          # update training loss\n",
        "          train_losses.append(loss.item()*data.size(0))\n",
        "          # clear the gradients of all optimized variables\n",
        "          optimizer.zero_grad()\n",
        "          if count==0:\n",
        "              train_pred=pred\n",
        "              train_target=target.data.view_as(pred)\n",
        "              count=count+1\n",
        "          else:\n",
        "              train_pred=torch.cat((train_pred,pred), 0)\n",
        "              train_target=torch.cat((train_target,target.data.view_as(pred)), 0)\n",
        "      train_pred = train_pred.cpu().view(-1).numpy().tolist()\n",
        "      train_target = train_target.cpu().view(-1).numpy().tolist()\n",
        "      ######################    \n",
        "      # validate the model #\n",
        "      ######################\n",
        "      model.eval()\n",
        "      for data, target in tqdm(valid_loader):\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          output = model(data)\n",
        "          # calculate the batch loss\n",
        "          loss =criterion(output, target)\n",
        "          #calculate accuracy\n",
        "          pred = output.data.max(dim = 1, keepdim = True)[1]\n",
        "          val_correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "          val_total += data.size(0)\n",
        "          valid_losses.append(loss.item()*data.size(0))\n",
        "          if count2==0:\n",
        "              val_pred=pred\n",
        "              val_target=target.data.view_as(pred)\n",
        "              count2=count+1\n",
        "          else:\n",
        "              val_pred=torch.cat((val_pred,pred), 0)\n",
        "              val_target=torch.cat((val_target,target.data.view_as(pred)), 0)\n",
        "      val_pred=val_pred.cpu().view(-1).numpy().tolist()\n",
        "      val_target=val_target.cpu().view(-1).numpy().tolist()\n",
        "      \n",
        "      # calculate average losses\n",
        "      train_loss=np.average(train_losses)\n",
        "      valid_loss=np.average(valid_losses)\n",
        "      \n",
        "      # calculate average accuracy\n",
        "      train_acc=train_correct/train_total\n",
        "      valid_acc=val_correct/val_total\n",
        "      train_acc_his.append(train_acc)\n",
        "      valid_acc_his.append(valid_acc)\n",
        "      train_losses_his.append(train_loss)\n",
        "      valid_losses_his.append(valid_loss)\n",
        "      # print training/validation statistics \n",
        "      print('\\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "          train_loss, valid_loss))\n",
        "      print('\\tTraining Accuracy: {:.6f} \\tValidation Accuracy: {:.6f}'.format(\n",
        "          train_acc, valid_acc))\n",
        "  return train_acc_his,valid_acc_his,train_losses_his,valid_losses_his,model"
      ],
      "metadata": {
        "id": "qdR1NvEv74nH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1=CNN_Model()\n",
        "n_epochs = 10\n",
        "optimizer1 = torch.optim.Adam(model1.parameters(), lr=LR)\n",
        "criterion = CrossEntropyLoss()\n",
        "train_acc_his,valid_acc_his,train_losses_his,valid_losses_his,model1=train(model1,n_epochs,train_loader,valid_loader,optimizer1,criterion)"
      ],
      "metadata": {
        "id": "XjN9vt59ACZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "plt.subplot(221)\n",
        "plt.plot(train_losses_his, 'bo', label = 'training loss')\n",
        "plt.plot(valid_losses_his, 'r', label = 'validation loss')\n",
        "plt.title(\"Simple CNN Loss\")\n",
        "plt.legend(loc='upper left')\n",
        "plt.subplot(222)\n",
        "plt.plot(train_acc_his, 'bo', label = 'training accuracy')\n",
        "plt.plot(valid_acc_his, 'r', label = 'validation accuracy')\n",
        "plt.title(\"Simple CNN Accuracy\")\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()\n",
        "torch.save(model1.state_dict(), \"/content/drive/MyDrive/img/human_detect.pt\")"
      ],
      "metadata": {
        "id": "exE2wpfwAJkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, path):\n",
        "  model.eval()\n",
        "  for filename in listdir(path):\n",
        "    img = Image.open(\"/content/drive/MyDrive/img/test/\" + filename).convert('RGB')\n",
        "    display(img)\n",
        "    transform = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()])     \n",
        "    img = transform(img)\n",
        "    img = img.unsqueeze(0)\n",
        "    with torch.no_grad(): \n",
        "      output = model(img)\n",
        "    if output[0][0] > output[0][1]:\n",
        "      print(\"clear\")\n",
        "    else:\n",
        "      print(\"crossing\")\n",
        "  return"
      ],
      "metadata": {
        "id": "w-uYR2rnsQ5G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_test=\"/content/drive/MyDrive/img/test\"\n",
        "TEST = Path(PATH_test)\n",
        "model = CNN_Model()\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/img/human_detect.pt'))\n",
        "test(model, TEST)"
      ],
      "metadata": {
        "id": "UguQ2T7Uull-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}